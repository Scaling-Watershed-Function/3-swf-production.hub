hmaxn = log(nrow(iml))
ic_loc[j,1]=yjn
ic_loc[j,2]=hn
ic_loc[j,3]=hmaxn
ic_loc[j,4]=yjn%*%(hmaxn-hn)
}
ag_list[[i]] <- ic_loc[1,]
fr_list[[i]] <- ic_loc[2,]
sr_list[[i]] <- ic_loc[3,]
ub_list[[i]] <- ic_loc[4,]
wt_list[[i]] <- ic_loc[5,]
}
ag_l = as_tibble(do.call("rbind",ag_list))
ag_l <- ag_l %>% mutate(use="Agriculture")
fr_l = as_tibble(do.call("rbind",fr_list))
fr_l <- fr_l %>% mutate(use = "Forests")
sr_l = as_tibble(do.call("rbind",sr_list))
sr_l <- sr_l %>% mutate(use = "Shurblands")
ub_l = as_tibble(do.call("rbind",ub_list))
ub_l <- ub_l %>% mutate(use = "Urban")
wt_l = as_tibble(do.call("rbind",wt_list))
wt_l <- wt_l %>% mutate(use = "Wetlands")
ywb_local_im <- rbind(ag_l,fr_l,sr_l,ub_l,wt_l) # Notice the "ywb" prefix in the name
p5 <- ggplot(ywb_local_im,aes(x = reorder(use,-In_l), y = In_l, fill = use, color = use))+
geom_boxplot(alpha = 0.5)+
scale_color_manual(values = my_colors)+
scale_fill_manual(values = my_colors)+
labs(x="Land use",y ="Information Contribution")+
theme(legend.position = "none")+
ggtitle("Information contribution across River Basins (Local Drainage Area)")
p5
librarian::shelf(tidyverse,#(includes ggplot2, readr, dplyr, tidyr, and more...)
entropy, usethis)
library("usethis")
git_sitrep() # git situation report
usethis::create_github_token()
gitcreds::gitcreds_set()
usethis::git_sitrep()
git_token_help()
credentials::git_credentials_forget()
library("usethis")
git_sitrep() # git situation report
credentials::git_credentials_forget()
git_credentials_forget()
usethis::git_credentials_forget()
library("credentials")
install.packages("credentials")
library("usethis")
library("credentials")
###############################################################################
# Scaling Analysis for Respiration Rates across the Yakima and Willamette River
# Basins
# DATA PREPARATION
###############################################################################
# RESPIRATION DATA
###############################################################################
#By : Francisco Guerrero
#Data source: SWAT-NEXXS Model simulations (By Kyongho Son)
#Loading packages:
# Run for the first time only
#install.packages("librarian")
#To run this code in macOS it is necessary to install XQuartz from
#www.xquartz.org
librarian::shelf(tidyverse, GGally) #it searches for the packages in your library,
#if you don't have them installed, it will proceed with the installation and it
#will bring them into your work space (like library will commonly do).
set.seed(2703)
# Data:
#values
#Yakima River Basin (yrb)
yrb_lgc_o <- read.csv("assets/data/raw/220725_yrb_resp_vars_legacy.csv",
stringsAsFactors = TRUE) #Dataset used for the AGU poster with uncorrected cumulative values
#i.e. respiration rates were not normalized by watershed area)
yrb_spt_o <- read.csv("assets/data/raw/230110_yrb_spatial_camp.csv",
stringsAsFactors = TRUE) #Predicted respiration rates at field locations
yrb_rsp_o <- read.csv("assets/data/raw/230116_yrb_respt_vars.csv",
stringsAsFactors = TRUE) #Updated dataset with corrected cumulative values
yrb_hbc_o <- read.csv("assets/data/raw/230117_yrb_hbgc_vars.csv",
stringsAsFactors = TRUE) #Hydro-biogeochemical variables (including residence
#time and hyporheic exchange)
#Willamette River Basin (wlm)
#Unlike the yrb datasets, the wlm datasets for both respiration (rsp) and hydro-biogeochemical
#variables (hbc) are split into two different datasets. To keep the naming across datasets
#consistent, I'm using "_o" for original and "_i" as a sequential index for other raw datasets
#that would be merged under the labels "rsp" or "hbc".
wlm_rsp_o <- read.csv("assets/data/raw/cum_resp_WM_mass_data_0116_2023.csv",
stringsAsFactors = TRUE)
wlm_rsp_i <- read.csv("assets/data/raw/model_resp_wm_rf0116.csv", stringsAsFactors = TRUE)
wlm_hbc_o <- read.csv("assets/data/raw/nhd_WM_streamdatabase_annual_resp_mass_01162023.csv",
stringsAsFactors = TRUE)
wlm_hbc_i <- read.csv("assets/data/raw/model_resp_annual_wm_input_output_df_01_16_2023.csv",
stringsAsFactors = TRUE)
# Re-ordering Willamette River Basin Data
#The data from the Willamette River Basin were provided by K. Son in different
#spreadsheets and organization compared to the YRB. We are going to start by
#reorganizing these data sets so that we could easily bind them with the YRB
#data sets.
#First, let's take a look into the column names for the respiration data from
#YRB
var_names <- colnames(yrb_rsp_o)
# [1] "COMID"                       "FromNode"                    "ToNode"                      "Hydrosq"
# [5] "CAT_STREAM_LENGTH"           "CAT_STREAM_SLOPE"            "TOT_STREAM_LENGTH"           "TOT_STREAM_SLOPE"
# [9] "CAT_BASIN_AREA"              "TOT_BASIN_AREA"              "pred_stream_area_m2_fill"    "pred_logw_m"
# [13] "stream_length_m"             "cum_totco2g_day"             "cum_stream_area_m2"          "cum_stream_length_m"
# [17] "cum_totco2g_day_Tsurface_m2" "cum_totco2g_day_Tdrain_m2"
#Second, we need to identify where these variables are stored withing the WLM
#datasets
glimpse(wlm_rsp_o)
glimpse(wlm_rsp_i)
glimpse(wlm_hbc_o)
glimpse(wlm_hbc_i)
#Let's pull the needed columns from each dataset (adding "m" at the end for "merging" within
#the same basin)
wlm_hbc_om <- dplyr::select(wlm_hbc_o,COMID,CAT_STREAM_SLOPE,TOT_STREAM_SLOPE,TOT_BASIN_AREA)
wlm_hbc_im <- dplyr::select(wlm_hbc_i,COMID,TotDASqKM,length_m)
wlm_rsp_om <- dplyr::select(wlm_rsp_o,COMID,FromNode,ToNode,cum_totco2g_day,cum_stream_area_m2,
cum_stream_length_m, cum_totco2g_day_Tdrain_m2, cum_totco2g_day_Tsurface_m2)
wlm_rsp_im <- dplyr::select(wlm_rsp_i,COMID,totco2g_day_fill,pred_stream_area_m2_fill,stream_length_m)
#Since merge only takes two inputs at a time, we have to merge our data sets sequentially
wlm_hbc_mg <- unique(merge(wlm_hbc_om,wlm_hbc_im,by = "COMID"))
wlm_rsp_mg <- unique(merge(wlm_rsp_om,wlm_rsp_im,by = "COMID"))
wlm_rsp_mg0 <- unique(merge(wlm_rsp_mg,wlm_hbc_mg,by="COMID"))
wlm_rsp_mg0$pred_logw_m <- log((wlm_rsp_mg0$pred_stream_area_m2_fill/wlm_rsp_mg0$stream_length_m),10)
#We will now reorganize columns to bind the YRM and WLM datasets
yrb_rsp_m1 <- dplyr::select(yrb_rsp_o,
COMID,
FromNode,
ToNode,
TOT_BASIN_AREA,
stream_length_m,
pred_logw_m,
pred_stream_area_m2_fill,
cum_stream_length_m,
cum_stream_area_m2,
cum_totco2g_day,
cum_totco2g_day_Tsurface_m2,
cum_totco2g_day_Tdrain_m2)
wlm_rsp_m1 <- dplyr::select(wlm_rsp_mg0,
COMID,
FromNode,
ToNode,
TOT_BASIN_AREA,
stream_length_m,
pred_logw_m,
pred_stream_area_m2_fill,
cum_stream_length_m,
cum_stream_area_m2,
cum_totco2g_day,
cum_totco2g_day_Tsurface_m2,
cum_totco2g_day_Tdrain_m2)
yrb_rsp_m1$basin <- "Yakima"
wlm_rsp_m1$basin <- "Willamette"
#Merging with additional hydro-biogeochemical data for both watersheds
yrb_hbc_m1 <- select(yrb_hbc_o,
COMID,
StreamOrde,
logQ_m3_div_s,
logwbkf_m,
logd_m,
logdbkf_m,
D50_m,
pred_annual_DOC,
pred_annual_DO,
no3_conc_mg_l,
logRT_total_hz_s,
logq_hz_total_m_s)
wlm_hbc_m1 <- select(wlm_hbc_i,
COMID,
StreamOrde,
logQ_m3_div_s,
logwbkf_m,
logd_m,
logdbkf_m,
D50_m,
pred_annual_DOC,
pred_annual_DO,
no3_conc_mg_l,
logRT_total_hz_s,
logq_hz_total_m_s)
yrb_rsp_m2 <- unique(merge(yrb_rsp_m1,yrb_hbc_m1,by = "COMID"))
wlm_rsp_m2 <- unique(merge(wlm_rsp_m1,wlm_hbc_m1,by = "COMID"))
yrb_wlm_rsp <- rbind(yrb_rsp_m2,wlm_rsp_m2)
p0 <- ggplot(yrb_wlm_rsp,aes(TOT_BASIN_AREA,cum_totco2g_day_Tdrain_m2,color = basin))+
geom_point(alpha = 0.35)+
scale_x_log10()+
scale_y_log10()+
geom_abline(slope = 0.5, intercept =-4.25,linetype = "dashed")+
geom_abline(slope = 1, intercept =-3,linetype = "solid")+
geom_abline(slope = 1.5, intercept =-1.75,linetype = "dashed")+
facet_wrap(~basin, ncol = 2)
p0
yrb_wlm_rsp %>% select(COMID,
basin,
TOT_BASIN_AREA,
cum_stream_area_m2,
cum_stream_length_m) %>%
gather(key = "variable",value = "value",c(4:5),factor_key = TRUE) %>%
ggplot(aes(TOT_BASIN_AREA,value,color=variable))+
geom_smooth(method = "lm")+
scale_x_log10()+
scale_y_log10()+
geom_abline(slope = 1, intercept = 2.95, linetype = "dashed")+
facet_wrap(~basin,ncol = 2)
yrb_wlm_rsp %>% select(COMID,
basin,
TOT_BASIN_AREA,
pred_stream_area_m2_fill,
StreamOrde,
logQ_m3_div_s,
D50_m,
logRT_total_hz_s,
logq_hz_total_m_s) %>%
mutate(logwsd_are = log(TOT_BASIN_AREA,10),
logstm_are = log(pred_stream_area_m2_fill,10),
logd50_m = log(D50_m,10),
logq_m3 = logQ_m3_div_s,10) %>%
ggpairs(columns = 8:12,
aes(color = basin ,alpha = 0.05))
###############################################################################
# Scaling Analysis for Respiration Rates across the Yakima River Basin
# LANDSCAPE HETEROGENEITY ANALYSIS
###############################################################################
#By : Francisco Guerrero
#Data source: Data sets generated with "script_data_prep_wlm_yrb.R"
#Loading packages:
#Run for the first time only
#install.packages(librarian)
# To run this code in macos it is necessary to install XQuartz from
#www.xquartz.org
librarian::shelf(tidyverse,#(includes ggplot2, readr, dplyr, tidyr, and more...)
entropy, usethis)
set.seed(2703)
# Tentative color palette for land uses (to be changed using colors corresponding
# to the national database)
my_colors <- c("#F564E3","#00BA38","#B79F00","#F8766D","#619CFF")
#Data:
dat_o <- read.csv("assets/data/processed/230202_yrb_wlm_resp_dat.csv",stringsAsFactors = TRUE)
lnd_o <- read.csv("assets/data/processed/230202_yrb_wlm_land_filtered_dat.csv",stringsAsFactors=TRUE)
#Let's first create a working data set, which right now is just
#a copy of the original lnd:
dat <- as_tibble(dat_o)
lnd <- as_tibble(lnd_o)
###############################################################################
# Scaling Analysis for Respiration Rates across the Yakima River Basin
# LANDSCAPE HETEROGENEITY ANALYSIS
###############################################################################
#By : Francisco Guerrero
#Data source: Data sets generated with "script_data_prep_wlm_yrb.R"
#Loading packages:
#Run for the first time only
#install.packages(librarian)
# To run this code in macos it is necessary to install XQuartz from
#www.xquartz.org
librarian::shelf(tidyverse,#(includes ggplot2, readr, dplyr, tidyr, and more...)
entropy, usethis)
set.seed(2703)
# Tentative color palette for land uses (to be changed using colors corresponding
# to the national database)
my_colors <- c("#F564E3","#00BA38","#B79F00","#F8766D","#619CFF")
#Data:
dat_o <- read.csv("assets/data/processed/230202_yrb_wlm_resp_dat.csv",stringsAsFactors = TRUE)
lnd_o <- read.csv("assets/data/processed/230202_yrb_wlm_land_filtered_dat.csv",stringsAsFactors=TRUE)
#Let's first create a working data set, which right now is just
#a copy of the original lnd:
dat <- as_tibble(dat_o)
lnd <- as_tibble(lnd_o)
################################################################################
# Entropy analysis
################################################################################
# Let's start with a simple calculation of the Shannon's entropy as a proxy for
# land use heterogeneity
# Making row-wise operations (https://dplyr.tidyverse.org/articles/rowwise.html)
lnd <- lnd %>% rowwise() %>%
mutate(hl = entropy(c(agrc,
frst,
shrb,
urbn,
wtnd),unit = "log")) %>%
mutate(hrl = hl/log(5)) %>%
mutate(ht = entropy(c(agrc_t,
frst_t,
shrb_t,
urbn_t,
wtnd_t),unit = "log")) %>%
mutate(hrt = ht/log(5))
# Let's compare basins in terms of their landscape heterogeneity:
lnd %>% select(basin,hrl,hrt) %>%
rename(Basin = basin,
Local = hrl,
Total = hrt) %>%
gather(key = "Extent",value = "Entropy",c(2:3)) %>%
ggplot(aes(Basin,Entropy,color = Basin))+
geom_boxplot(alpha = 0.5)+
ylab("Relative Shannon's Entropy")+
facet_wrap(~Extent,ncol = 2)
# Despite the striking differences in landscape configuration, we do not observe
# a commensurate difference in landscape entropies.
# Information content analysis
# Using Shannon's entropy calculations, we can identify which land use types
# either locally or at the watershed scale contribute with most of the information
# about spatial variability.
# We are going to use re sampling to estimate the uncertainty about the information
# contribution from the land use components.
# Let's start with local analysis
# Willamette River Basin
# Local data set
lnd_el <- filter(lnd,basin == "Willamette") %>% #Notice the specification of the watershed of interest
select(agrc,
frst,
shrb,
urbn,
wtnd)
# Creating a matrix for results
ncols = 4
nrows = 5
ssz = 1000
ic_loc <- matrix(1:nrows,nrows,ncols,
dimnames = list(c("Agriculture","Forests","Shrublands","Urban","Wetlands"),
c("Yjn_l","Hn_l","Hmaxn_l", "In_l")))
ag_list <- list()
fr_list <- list()
sr_list <- list()
ub_list <- list()
wt_list <- list()
# Number of iterations
itn = 1000
for(i in 1:itn){
if (i == itn +1){
break
}
loc_im <- lnd_el[sample(nrow(lnd_el),size=ssz,replace = FALSE),]
iml <- loc_im[,c(1:ncol(loc_im))]/sum(loc_im[,c(1:ncol(loc_im))])
for(j in 1:ncol(iml)){
yjn = sum(iml[,j])
hn = entropy(iml[,j], unit = "log")
hmaxn = log(nrow(iml))
ic_loc[j,1]=yjn
ic_loc[j,2]=hn
ic_loc[j,3]=hmaxn
ic_loc[j,4]=yjn%*%(hmaxn-hn)
}
ag_list[[i]] <- ic_loc[1,]
fr_list[[i]] <- ic_loc[2,]
sr_list[[i]] <- ic_loc[3,]
ub_list[[i]] <- ic_loc[4,]
wt_list[[i]] <- ic_loc[5,]
}
ag_l = as_tibble(do.call("rbind",ag_list))
ag_l <- ag_l %>% mutate(use="Agriculture")
fr_l = as_tibble(do.call("rbind",fr_list))
fr_l <- fr_l %>% mutate(use = "Forests")
sr_l = as_tibble(do.call("rbind",sr_list))
sr_l <- sr_l %>% mutate(use = "Shurblands")
ub_l = as_tibble(do.call("rbind",ub_list))
ub_l <- ub_l %>% mutate(use = "Urban")
wt_l = as_tibble(do.call("rbind",wt_list))
wt_l <- wt_l %>% mutate(use = "Wetlands")
wlm_local_im <- rbind(ag_l,fr_l,sr_l,ub_l,wt_l) # Notice the "wlm" prefix in the name
# of the output file
# Let's check the results with a box-plot
p5 <- ggplot(wlm_local_im,aes(x = reorder(use,-In_l), y = In_l, fill = use, color = use))+
geom_boxplot(alpha = 0.5)+
scale_color_manual(values = my_colors)+
scale_fill_manual(values = my_colors)+
labs(x="Land use",y ="Information Contribution")+
theme(legend.position = "none")+
ggtitle("Willamette River Basin (Local Drainage Area)")
p5
# Local data set
lnd_el <- filter(lnd,basin == "Yakima") %>% #Notice the specification of the watershed of interest
select(agrc,
frst,
shrb,
urbn,
wtnd)
# Creating a matrix for results
ncols = 4
nrows = 5
ssz = 1000
ic_loc <- matrix(1:nrows,nrows,ncols,
dimnames = list(c("Agriculture","Forests","Shrublands","Urban","Wetlands"),
c("Yjn_l","Hn_l","Hmaxn_l", "In_l")))
ag_list <- list()
fr_list <- list()
sr_list <- list()
ub_list <- list()
wt_list <- list()
# Number of iterations
itn = 1000
for(i in 1:itn){
if (i == itn +1){
break
}
loc_im <- lnd_el[sample(nrow(lnd_el),size=ssz,replace = FALSE),]
iml <- loc_im[,c(1:ncol(loc_im))]/sum(loc_im[,c(1:ncol(loc_im))])
for(j in 1:ncol(iml)){
yjn = sum(iml[,j])
hn = entropy(iml[,j], unit = "log")
hmaxn = log(nrow(iml))
ic_loc[j,1]=yjn
ic_loc[j,2]=hn
ic_loc[j,3]=hmaxn
ic_loc[j,4]=yjn%*%(hmaxn-hn)
}
ag_list[[i]] <- ic_loc[1,]
fr_list[[i]] <- ic_loc[2,]
sr_list[[i]] <- ic_loc[3,]
ub_list[[i]] <- ic_loc[4,]
wt_list[[i]] <- ic_loc[5,]
}
ag_l = as_tibble(do.call("rbind",ag_list))
ag_l <- ag_l %>% mutate(use="Agriculture")
fr_l = as_tibble(do.call("rbind",fr_list))
fr_l <- fr_l %>% mutate(use = "Forests")
sr_l = as_tibble(do.call("rbind",sr_list))
sr_l <- sr_l %>% mutate(use = "Shurblands")
ub_l = as_tibble(do.call("rbind",ub_list))
ub_l <- ub_l %>% mutate(use = "Urban")
wt_l = as_tibble(do.call("rbind",wt_list))
wt_l <- wt_l %>% mutate(use = "Wetlands")
yrb_local_im <- rbind(ag_l,fr_l,sr_l,ub_l,wt_l) # Notice the "yrb" prefix in the name
# of the output file
# Let's check the results with a box-plot
p5 <- ggplot(yrb_local_im,aes(x = reorder(use,-In_l), y = In_l, fill = use, color = use))+
geom_boxplot(alpha = 0.5)+
scale_color_manual(values = my_colors)+
scale_fill_manual(values = my_colors)+
labs(x="Land use",y ="Information Contribution")+
theme(legend.position = "none")+
ggtitle("Yakima River Basin (Local Drainage Area)")
p5
# Overall (Local Information Contribution)
# Local data set
lnd_el <- lnd %>% #Notice that no watershed is specified in the analysis
select(agrc,
frst,
shrb,
urbn,
wtnd)
# Creating a matrix for results
ncols = 4
nrows = 5
ssz = 1400
ic_loc <- matrix(1:nrows,nrows,ncols,
dimnames = list(c("Agriculture","Forests","Shrublands","Urban","Wetlands"),
c("Yjn_l","Hn_l","Hmaxn_l", "In_l")))
ag_list <- list()
fr_list <- list()
sr_list <- list()
ub_list <- list()
wt_list <- list()
# Number of iterations
itn = 5000
for(i in 1:itn){
if (i == itn +1){
break
}
loc_im <- lnd_el[sample(nrow(lnd_el),size=ssz,replace = FALSE),]
iml <- loc_im[,c(1:ncol(loc_im))]/sum(loc_im[,c(1:ncol(loc_im))])
for(j in 1:ncol(iml)){
yjn = sum(iml[,j])
hn = entropy(iml[,j], unit = "log")
hmaxn = log(nrow(iml))
ic_loc[j,1]=yjn
ic_loc[j,2]=hn
ic_loc[j,3]=hmaxn
ic_loc[j,4]=yjn%*%(hmaxn-hn)
}
ag_list[[i]] <- ic_loc[1,]
fr_list[[i]] <- ic_loc[2,]
sr_list[[i]] <- ic_loc[3,]
ub_list[[i]] <- ic_loc[4,]
wt_list[[i]] <- ic_loc[5,]
}
ag_l = as_tibble(do.call("rbind",ag_list))
ag_l <- ag_l %>% mutate(use="Agriculture")
fr_l = as_tibble(do.call("rbind",fr_list))
fr_l <- fr_l %>% mutate(use = "Forests")
sr_l = as_tibble(do.call("rbind",sr_list))
sr_l <- sr_l %>% mutate(use = "Shurblands")
ub_l = as_tibble(do.call("rbind",ub_list))
ub_l <- ub_l %>% mutate(use = "Urban")
wt_l = as_tibble(do.call("rbind",wt_list))
wt_l <- wt_l %>% mutate(use = "Wetlands")
ywb_local_im <- rbind(ag_l,fr_l,sr_l,ub_l,wt_l) # Notice the "ywb" prefix in the name
# of the output file
# Let's check the results with a box-plot
p5 <- ggplot(ywb_local_im,aes(x = reorder(use,-In_l), y = In_l, fill = use, color = use))+
geom_boxplot(alpha = 0.5)+
scale_color_manual(values = my_colors)+
scale_fill_manual(values = my_colors)+
labs(x="Land use",y ="Information Contribution")+
theme(legend.position = "none")+
ggtitle("Information contribution across River Basins (Local Drainage Area)")
p5
library("usethis")
library("credentials")
git_sitrep() # git situation report
usethis::create_github_token()
usethis::create_github_token()
gitcreds::gitcreds_set()
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
gitcreds::gitcreds_set()
usethis::git_sitrep()
gh_token_help()
git_sitrep() # git situation report
usethis::create_github_token()
git_sitrep() # git situation report
usethis::create_github_token()
gitcreds::gitcreds_set()
usethis::git_sitrep()
usethis::git_credentials_forget()
